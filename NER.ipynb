{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "M97cx4WWRhak",
   "metadata": {
    "id": "M97cx4WWRhak"
   },
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xmKu716aMOnu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmKu716aMOnu",
    "outputId": "9512a4c6-4512-4c3b-b209-79bb41f84705"
   },
   "outputs": [],
   "source": [
    "!wget -O train.jsonl \"https://huggingface.co/datasets/iluvvatar/NEREL/resolve/main/data/train.jsonl\"\n",
    "!wget -O dev.jsonl   \"https://huggingface.co/datasets/iluvvatar/NEREL/resolve/main/data/dev.jsonl\"\n",
    "!wget -O test.jsonl  \"https://huggingface.co/datasets/iluvvatar/NEREL/resolve/main/data/test.jsonl\"\n",
    "\n",
    "!wget -O ent_types.jsonl \"https://huggingface.co/datasets/iluvvatar/NEREL/resolve/main/ent_types.jsonl\"\n",
    "!wget -O rel_types.jsonl \"https://huggingface.co/datasets/iluvvatar/NEREL/resolve/main/rel_types.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd5eb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3dd5eb2",
    "outputId": "80c12577-c725-4662-dd42-298b896981a5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# данные\n",
    "train_path = \"train.jsonl\"\n",
    "records = []\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 200:\n",
    "            break\n",
    "        records.append(json.loads(line))\n",
    "\n",
    "print(f\"Загружено {len(records)} записей\")\n",
    "print(records[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66ed78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f66ed78",
    "outputId": "9f1356c9-f278-4441-aada-1768bf17e8a0"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "entity_counter = Counter()\n",
    "relation_counter = Counter()\n",
    "text_lengths = []\n",
    "entities_per_doc = []\n",
    "\n",
    "for rec in records:\n",
    "    text = rec[\"text\"]\n",
    "    ents = rec.get(\"entities\", [])\n",
    "    rels = rec.get(\"relations\", [])\n",
    "\n",
    "    text_lengths.append(len(text.split()))\n",
    "    entities_per_doc.append(len(ents))\n",
    "\n",
    "    # entities\n",
    "    for e in ents:\n",
    "        parts = e.split(\"\\t\")\n",
    "        ent_info = parts[1].split()\n",
    "        ent_type = ent_info[0]\n",
    "        entity_counter[ent_type] += 1\n",
    "\n",
    "    # relations\n",
    "    for r in rels:\n",
    "        parts = r.split(\"\\t\")\n",
    "        rel_type = parts[1].split()[0]\n",
    "        relation_counter[rel_type] += 1\n",
    "\n",
    "print(\"Топ 20 типов сущностей:\", entity_counter.most_common(20))\n",
    "print(\"Топ 20 типов отношений:\", relation_counter.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534824bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "534824bd",
    "outputId": "4ba708e6-c60b-4ac2-b5cd-207e3d860fc9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", font=\"DejaVu Sans\")\n",
    "\n",
    "# топ 15 типов сущностей\n",
    "top_entities = entity_counter.most_common(15)\n",
    "df_entities = pd.DataFrame(top_entities, columns=[\"Entity\", \"Count\"])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=df_entities, x=\"Count\", y=\"Entity\", palette=\"viridis\")\n",
    "plt.title(\"Топ 15 типов сущностей\")\n",
    "plt.xlabel(\"Частота\")\n",
    "plt.ylabel(\"Тип сущности\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# распределение длины текстов\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(text_lengths, bins=30, kde=False)\n",
    "plt.xlabel(\"Длина текста (в словах)\")\n",
    "plt.ylabel(\"Количество документов\")\n",
    "plt.title(\"Распределение длины текстов\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# распределение числа сущностей на документ\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(entities_per_doc, bins=30, kde=False)\n",
    "plt.xlabel(\"Число сущностей на документ\")\n",
    "plt.ylabel(\"Количество документов\")\n",
    "plt.title(\"Распределение числа сущностей\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9954f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "ac9954f1",
    "outputId": "48a4ad43-c1d3-466b-8cc5-ddcda230fddf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(\"\"\"\n",
    "### Выводы\n",
    "1. В корпусе встречаются очень частые типы сущностей (PERSON, PROFESSION etc.), но и редкие типы (AWARD, IDEOLOGY), может возникнуть дисбаланс классов.\n",
    "2. Длина документов стакже неравномерно распределена: есть и короткие тексты, и длинные, поэтому при моделировании важно применить padding, truncation.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kF3_nlJtL2u9",
   "metadata": {
    "id": "kF3_nlJtL2u9"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Функции парсинга строкового формата NEREL\n",
    "def parse_entity_line(line: str):\n",
    "    parts = line.split('\\t')\n",
    "    if len(parts) < 3:\n",
    "        return None\n",
    "    ent_id = parts[0].strip()\n",
    "    type_pos = parts[1].strip()\n",
    "    text = parts[2].strip() if len(parts) > 2 else ''\n",
    "    m = re.match(r'(\\S+)\\s+(\\d+)\\s+(\\d+)', type_pos)\n",
    "    if not m:\n",
    "        return None\n",
    "    ent_type = m.group(1)\n",
    "    start = int(m.group(2))\n",
    "    end = int(m.group(3))\n",
    "    return {'id': ent_id, 'type': ent_type, 'start': start, 'end': end, 'text': text}\n",
    "\n",
    "def parse_relation_line(line: str):\n",
    "    parts = line.split('\\t')\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    rel_id = parts[0].strip()\n",
    "    body = parts[1].strip()\n",
    "    m = re.match(r'(\\S+)\\s+Arg1:(\\S+)\\s+Arg2:(\\S+)', body)\n",
    "    if not m:\n",
    "        return None\n",
    "    rel_type = m.group(1)\n",
    "    arg1 = m.group(2); arg2 = m.group(3)\n",
    "    return {'id': rel_id, 'type': rel_type, 'arg1': arg1, 'arg2': arg2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664a79d",
   "metadata": {
    "id": "3664a79d"
   },
   "outputs": [],
   "source": [
    "def whitespace_tokenize_with_offsets(text: str):\n",
    "    tokens = []\n",
    "    spans = []\n",
    "    pos = 0\n",
    "    for tok in text.split():\n",
    "        start = text.find(tok, pos)\n",
    "        end = start + len(tok)\n",
    "        tokens.append(tok)\n",
    "        spans.append((start, end))\n",
    "        pos = end\n",
    "    return tokens, spans\n",
    "\n",
    "\n",
    "def build_examples_from_nerel(records, event_list):\n",
    "    examples = []\n",
    "    event2idx = {ev: i for i, ev in enumerate(event_list)}\n",
    "\n",
    "    for rec in records:\n",
    "        text = rec[\"text\"]\n",
    "        tokens, token_spans = whitespace_tokenize_with_offsets(text)\n",
    "        token_labels = [\"O\"] * len(tokens)\n",
    "        cls_vec = [0] * len(event_list)\n",
    "\n",
    "        # сущности\n",
    "        for e in rec.get(\"entities\", []):\n",
    "            ent = parse_entity_line(e)\n",
    "            if not ent:\n",
    "                continue\n",
    "            span_start, span_end = ent[\"start\"], ent[\"end\"]\n",
    "\n",
    "            overlapping_idxs = []\n",
    "            for i, (t_start, t_end) in enumerate(token_spans):\n",
    "                if not (t_end <= span_start or t_start >= span_end):\n",
    "                    overlapping_idxs.append(i)\n",
    "\n",
    "            for j, tok_idx in enumerate(overlapping_idxs):\n",
    "                if token_labels[tok_idx] != \"O\":\n",
    "                    continue\n",
    "                prefix = \"B\" if j == 0 else \"I\"\n",
    "                token_labels[tok_idx] = f\"{prefix}-{ent['type']}\"\n",
    "\n",
    "        # отношения\n",
    "        for r in rec.get(\"relations\", []):\n",
    "            rel = parse_relation_line(r)\n",
    "            if not rel:\n",
    "                continue\n",
    "            if rel[\"type\"] in event2idx:\n",
    "                cls_vec[event2idx[rel[\"type\"]]] = 1\n",
    "\n",
    "        examples.append({\n",
    "            \"id\": rec[\"id\"],\n",
    "            \"text\": text,\n",
    "            \"tokens\": tokens,\n",
    "            \"token_spans\": token_spans,\n",
    "            \"tags\": token_labels,\n",
    "            \"cls_vec\": cls_vec\n",
    "        })\n",
    "\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1198e",
   "metadata": {
    "id": "50a1198e"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_event_list(records, K=30):\n",
    "    counter = Counter()\n",
    "    for rec in records:\n",
    "        for r in rec.get(\"relations\", []):\n",
    "            rel = parse_relation_line(r)\n",
    "            if rel:\n",
    "                counter[rel[\"type\"]] += 1\n",
    "\n",
    "    return [t for t, _ in counter.most_common(K)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2ce4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfe2ce4e",
    "outputId": "2208d1ed-5c44-43e2-f0bd-81c1d14aaf16"
   },
   "outputs": [],
   "source": [
    "event_list = make_event_list(records, K=30)\n",
    "print(\"События:\", event_list)\n",
    "\n",
    "examples = build_examples_from_nerel(records, event_list)\n",
    "print(\"Пример tokens, tags:\", examples[0][\"tokens\"][:15], examples[0][\"tags\"][:15])\n",
    "print(\"cls_vec:\", examples[0][\"cls_vec\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e460e1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e460e1b",
    "outputId": "3999df6b-5f4a-40a0-8aea-05eaec1121bf"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "unique_labels = set()\n",
    "for ex in examples:\n",
    "    unique_labels.update(ex[\"tags\"])\n",
    "unique_labels.add(\"O\")\n",
    "label_list = sorted(unique_labels)\n",
    "label2id = {lab: i for i, lab in enumerate(label_list)}\n",
    "id2label = {i: lab for lab, i in label2id.items()}\n",
    "\n",
    "for ex in examples:\n",
    "    ex[\"tags\"] = [label2id[t] for t in ex[\"tags\"]]\n",
    "\n",
    "full_ds = Dataset.from_list(examples)\n",
    "split = full_ds.train_test_split(test_size=0.1, seed=42)\n",
    "dataset = DatasetDict({\"train\": split[\"train\"], \"test\": split[\"test\"]})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7a387",
   "metadata": {
    "id": "10c7a387"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\", use_fast=True)\n",
    "\n",
    "def tokenize_and_align_labels(examples_batch, tokenizer, max_length=256):\n",
    "    tokenized = tokenizer(\n",
    "        examples_batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, word_labels in enumerate(examples_batch[\"tags\"]):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        prev_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != prev_word_idx:\n",
    "                label_ids.append(word_labels[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            prev_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    tokenized[\"cls_labels\"] = examples_batch[\"cls_vec\"]\n",
    "    tokenized.pop(\"offset_mapping\")\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506db2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "938e56f943df4c35a10b15be474e64ec",
      "e603b47036714655af805958cc63076a",
      "cdd29467165a40daa830daba1e91fd17",
      "852b1067fdf24a3fb2ec5af3c29815e9",
      "c52358d7b38f4f3db7f2f42cbbc43419",
      "8b13efd9432340babc6059fd1f656554",
      "8c284919bc114d6dbd674db00183d508",
      "cb0f56b4ab794d27807bdb043e288216",
      "954e0d237a1b45d0acd8ad8112f81be3",
      "3458397b098146e2a753b6d62950be3a",
      "df47ea0d0dc94fd4b8857b8f86648975",
      "c63cb1c59ba64c7e926ba6e4a70974cc",
      "9dc7a50f7ad2483d9ba05f5969fb4eef",
      "7d2b9279b077468d960b3dd7be69d708",
      "10da93ddd3e4410ca79baa62b16d119b",
      "7d878f0fb6ea44c49483a5ba56c4e168",
      "f63cec0c09234f27b6af5ea3fe947d83",
      "153daf231c684d779192efc7b6282044",
      "4abd3d15a7b24868948ae78b64a08cb3",
      "1fd9cf57b7694db68e139bd0feab60aa",
      "3336893c62e241dea515aaee540c04e9",
      "b6dae53ab3544a4a9e8b23b9528d7e8e"
     ]
    },
    "id": "8506db2c",
    "outputId": "2cc27d28-199a-4ce0-a8bd-2bbd98274c18"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenize_and_align_labels(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"tokens\", \"tags\", \"token_spans\", \"id\"]\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)\n",
    "print(tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaeb497",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbaeb497",
    "outputId": "8fbff563-1b77-4d1d-f5ae-14986d30a002"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "def custom_collator(batch):\n",
    "    features = [{\n",
    "        \"input_ids\": item[\"input_ids\"],\n",
    "        \"attention_mask\": item[\"attention_mask\"],\n",
    "        \"labels\": item[\"labels\"]\n",
    "    } for item in batch]\n",
    "\n",
    "    batch_enc = data_collator(features)\n",
    "\n",
    "    batch_enc[\"cls_labels\"] = torch.tensor([item[\"cls_labels\"] for item in batch], dtype=torch.float)\n",
    "\n",
    "    return batch_enc\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collator)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    collate_fn=custom_collator)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch.keys())\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    print(batch[\"labels\"].shape)\n",
    "    print(batch[\"cls_labels\"].shape)\n",
    "    break\n",
    "\n",
    "print(\"Готово. Примеры для обучения:\", len(tokenized_dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dsQobOKL2vA",
   "metadata": {
    "id": "8dsQobOKL2vA"
   },
   "source": [
    "##### Модель: `JointModel` + custom loss (uncertainty weighting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d84ea",
   "metadata": {
    "id": "ef3d84ea"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "class JointModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_name: str = \"DeepPavlov/rubert-base-cased\",\n",
    "        num_token_labels: int = 10,\n",
    "        num_cls_labels: int = 30,\n",
    "        dropout: float = 0.1,\n",
    "        use_uncertainty_weight: bool = True,\n",
    "        pos_weight_cls: torch.Tensor | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = AutoConfig.from_pretrained(encoder_name)\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        hidden = self.config.hidden_size\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.token_classifier = nn.Linear(hidden, num_token_labels)\n",
    "        self.cls_classifier   = nn.Linear(hidden, num_cls_labels)\n",
    "\n",
    "\n",
    "        self.token_loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        self.cls_loss_fct = nn.BCEWithLogitsLoss(pos_weight=pos_weight_cls)\n",
    "\n",
    "        self.use_uncertainty_weight = use_uncertainty_weight\n",
    "        self.log_sigma_token = nn.Parameter(torch.tensor(0.0))\n",
    "        self.log_sigma_cls   = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        labels: torch.Tensor | None = None,\n",
    "        cls_labels: torch.Tensor | None = None,\n",
    "    ):\n",
    "\n",
    "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        seq = enc.last_hidden_state\n",
    "        pooled = seq[:, 0, :]\n",
    "\n",
    "        seq = self.dropout(seq)\n",
    "        pooled = self.dropout(pooled)\n",
    "\n",
    "        token_logits = self.token_classifier(seq)\n",
    "        cls_logits   = self.cls_classifier(pooled)\n",
    "\n",
    "        out = {\"token_logits\": token_logits, \"cls_logits\": cls_logits}\n",
    "\n",
    "        if labels is not None and cls_labels is not None:\n",
    "            token_loss = self.token_loss_fct(\n",
    "                token_logits.view(-1, token_logits.size(-1)),\n",
    "                labels.view(-1)\n",
    "            )\n",
    "            cls_loss = self.cls_loss_fct(cls_logits, cls_labels.float())\n",
    "\n",
    "            if self.use_uncertainty_weight:\n",
    "                # exp(-2*log_sigma)*L + log_sigma\n",
    "                loss_token_term = torch.exp(-2.0 * self.log_sigma_token) * token_loss + self.log_sigma_token\n",
    "                loss_cls_term   = torch.exp(-2.0 * self.log_sigma_cls)   * cls_loss   + self.log_sigma_cls\n",
    "                loss = loss_token_term + loss_cls_term\n",
    "                out.update({\n",
    "                    \"loss\": loss,\n",
    "                    \"token_loss\": token_loss.detach(),\n",
    "                    \"cls_loss\": cls_loss.detach(),\n",
    "                    \"log_sigma_token\": self.log_sigma_token.detach(),\n",
    "                    \"log_sigma_cls\": self.log_sigma_cls.detach(),\n",
    "                })\n",
    "            else:\n",
    "                loss = token_loss + cls_loss\n",
    "                out.update({\n",
    "                    \"loss\": loss,\n",
    "                    \"token_loss\": token_loss.detach(),\n",
    "                    \"cls_loss\": cls_loss.detach(),\n",
    "                })\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8a614",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0b8a614",
    "outputId": "0caf7be5-0525-4210-b6ad-65b7669abe33"
   },
   "outputs": [],
   "source": [
    "num_token_labels = len(set(id2label.keys()))\n",
    "num_cls_labels   = len(examples[0][\"cls_vec\"])\n",
    "\n",
    "model = JointModel(\n",
    "    encoder_name=\"DeepPavlov/rubert-base-cased\",\n",
    "    num_token_labels=num_token_labels,\n",
    "    num_cls_labels=num_cls_labels,\n",
    "    dropout=0.1,\n",
    "    use_uncertainty_weight=True,\n",
    "    pos_weight_cls=None\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whOvhd8jL2vB",
   "metadata": {
    "id": "whOvhd8jL2vB"
   },
   "source": [
    "##### Training / Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae28e26",
   "metadata": {
    "id": "1ae28e26"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "epochs = 10\n",
    "lr = 5e-5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fab86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e57fab86",
    "outputId": "1ff5a60c-2fe1-4cf1-f850-5d3f301f3296"
   },
   "outputs": [],
   "source": [
    "!pip install seqeval\n",
    "from seqeval.metrics import f1_score as seqeval_f1\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_token_f1(preds, labels, id2label):\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for p, l in zip(preds, labels):\n",
    "        cur_true, cur_pred = [], []\n",
    "        for pi, li in zip(p, l):\n",
    "            if li == -100:\n",
    "                continue\n",
    "            cur_true.append(id2label[li])\n",
    "            cur_pred.append(id2label[pi])\n",
    "        true_labels.append(cur_true)\n",
    "        pred_labels.append(cur_pred)\n",
    "\n",
    "    return seqeval_f1(true_labels, pred_labels, average=\"macro\")\n",
    "\n",
    "def compute_cls_metrics(preds, labels):\n",
    "    preds_bin = (preds > 0).astype(int)\n",
    "    micro_f1 = f1_score(labels, preds_bin, average=\"micro\", zero_division=0)\n",
    "    prec = precision_score(labels, preds_bin, average=\"micro\", zero_division=0)\n",
    "    rec = recall_score(labels, preds_bin, average=\"micro\", zero_division=0)\n",
    "    return micro_f1, prec, rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db67e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8db67e9",
    "outputId": "542a7caf-1287-46a9-9967-8e12b714a92e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_table = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        cls_labels = batch[\"cls_labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(input_ids, attention_mask, labels=labels, cls_labels=cls_labels)\n",
    "        loss = out[\"loss\"]\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds_token, all_labels_token = [], []\n",
    "    all_preds_cls, all_labels_cls = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            cls_labels = batch[\"cls_labels\"].to(device)\n",
    "\n",
    "            out = model(input_ids, attention_mask)\n",
    "            token_logits = out[\"token_logits\"].cpu().numpy()\n",
    "            cls_logits = out[\"cls_logits\"].cpu().numpy()\n",
    "\n",
    "            # токены\n",
    "            preds = np.argmax(token_logits, axis=-1)\n",
    "            all_preds_token.extend(preds.tolist())\n",
    "            all_labels_token.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "            # cls\n",
    "            all_preds_cls.extend(cls_logits)\n",
    "            all_labels_cls.extend(cls_labels.cpu().numpy())\n",
    "\n",
    "    token_f1 = compute_token_f1(all_preds_token, all_labels_token, id2label)\n",
    "    cls_f1, cls_prec, cls_rec = compute_cls_metrics(np.array(all_preds_cls), np.array(all_labels_cls))\n",
    "\n",
    "    log_table.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": round(avg_train_loss, 4),\n",
    "        \"token_f1\": round(token_f1, 4),\n",
    "        \"cls_f1\": round(cls_f1, 4),\n",
    "        \"cls_prec\": round(cls_prec, 4),\n",
    "        \"cls_rec\": round(cls_rec, 4)\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch} | loss {avg_train_loss:.4f} | token-F1 {token_f1:.4f} | \"\n",
    "          f\"cls-F1 {cls_f1:.4f} | P {cls_prec:.4f} | R {cls_rec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a78a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "658a78a1",
    "outputId": "e492df5d-9038-42ae-db58-ad6cf0cf8633"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_log = pd.DataFrame(log_table)\n",
    "display(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9MpLuI60gf4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "9MpLuI60gf4f",
    "outputId": "f699d779-4205-4bdd-c304-35a1bd877fee"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(\"\"\"\n",
    "### Выводы\n",
    "1. Модель уверенно обучается: train loss падает от 0.54 до 0.29.\n",
    "2. CLS-задача стабильно даёт довольно высокий F1 ≈ 0.70 уже с первых эпох.\n",
    "3. Token-level F1 находится не на очень высоком уровне, значит выделение сущностей сложнее и требует дообучения.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_x6IVLrcL2vC",
   "metadata": {
    "id": "_x6IVLrcL2vC"
   },
   "source": [
    "##### Инференс, квантизация и анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rrm-S8s30RHK",
   "metadata": {
    "id": "rrm-S8s30RHK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def predict(model, tokenizer, text, id2label, cls_event_list, device=\"cpu\", max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text.split(),\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "    # токенные предсказания\n",
    "    token_logits = outputs[\"token_logits\"].cpu().numpy()[0]\n",
    "    pred_ids = np.argmax(token_logits, axis=-1)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    pred_labels = [\n",
    "        id2label[i] if mask == 1 else \"PAD\"\n",
    "        for i, (mask, i) in enumerate(zip(attention_mask[0].tolist(), pred_ids))\n",
    "    ]\n",
    "\n",
    "    # CLS вероятности\n",
    "    cls_logits = outputs[\"cls_logits\"].cpu().numpy()[0]\n",
    "    cls_probs = torch.sigmoid(torch.tensor(cls_logits)).numpy()\n",
    "    cls_pred = {cls_event_list[i]: float(cls_probs[i]) for i in range(len(cls_probs))}\n",
    "\n",
    "    return tokens, pred_labels, cls_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5plyhyp0XNR",
   "metadata": {
    "id": "f5plyhyp0XNR"
   },
   "outputs": [],
   "source": [
    "def qualitative_analysis(model, tokenizer, dataset, id2label, cls_event_list, n=10, device=\"cpu\"):\n",
    "    for i in range(n):\n",
    "        ex = dataset[i]\n",
    "        text = ex[\"text\"]\n",
    "        true_tags = [id2label[t] for t in ex[\"tags\"]]\n",
    "        true_cls = ex[\"cls_vec\"]\n",
    "\n",
    "        tokens, pred_tags, cls_pred = predict(model, tokenizer, text, id2label, cls_event_list, device=device)\n",
    "\n",
    "        print(f\"\\nПример {i+1}\")\n",
    "        print(\"Текст:\", text[:200], \"...\")\n",
    "        print(\"GT tags :\", true_tags[:20])\n",
    "        print(\"Pred tags:\", pred_tags[:20])\n",
    "\n",
    "        true_cls_labels = [cls_event_list[j] for j, v in enumerate(true_cls) if v == 1]\n",
    "        pred_cls_labels = [k for k, v in cls_pred.items() if v > 0.5]\n",
    "\n",
    "        print(\"GT CLS :\", true_cls_labels)\n",
    "        print(\"Pred CLS:\", pred_cls_labels)\n",
    "\n",
    "        fp = set(pred_cls_labels) - set(true_cls_labels)\n",
    "        fn = set(true_cls_labels) - set(pred_cls_labels)\n",
    "        if fp:\n",
    "            print(\"False Positives:\", fp)\n",
    "        if fn:\n",
    "            print(\"False Negatives:\", fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XEWzJPff0bbV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEWzJPff0bbV",
    "outputId": "f0cb8120-1dd6-49ac-b67e-6bf69c364a91"
   },
   "outputs": [],
   "source": [
    "qualitative_analysis(\n",
    "    model, tokenizer, dataset[\"test\"],\n",
    "    id2label=id2label, cls_event_list=event_list,\n",
    "    n=10, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OJN2Wm411SR7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJN2Wm411SR7",
    "outputId": "d41fd2c6-d81d-4a72-b43d-16b5f7191cf3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "\n",
    "model_cpu = model.to(\"cpu\").eval()\n",
    "\n",
    "# динамическая квантизация\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model_cpu, {nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print(\"Обычная модель (fp32):\")\n",
    "print(model_cpu)\n",
    "print(\"Квантизированная модель (int8):\")\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gVACdJ9z1dEO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVACdJ9z1dEO",
    "outputId": "d7495b59-4af4-40e6-e9d3-57e572926b06"
   },
   "outputs": [],
   "source": [
    "text = \"Россия и США подписали новое соглашение о ядерном разоружении.\"\n",
    "\n",
    "_ = predict(model_cpu, tokenizer, text, id2label, event_list)\n",
    "_ = predict(quantized_model, tokenizer, text, id2label, event_list)\n",
    "\n",
    "N = 50\n",
    "start = time.time()\n",
    "for _ in range(N):\n",
    "    _ = predict(model_cpu, tokenizer, text, id2label, event_list)\n",
    "time_fp32 = (time.time() - start) / N\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(N):\n",
    "    _ = predict(quantized_model, tokenizer, text, id2label, event_list)\n",
    "time_int8 = (time.time() - start) / N\n",
    "\n",
    "print(f\"Среднее время fp32: {time_fp32*1000:.2f} ms\")\n",
    "print(f\"Среднее время int8: {time_int8*1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LxXPJscU1lK3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxXPJscU1lK3",
    "outputId": "9ffdbaee-8248-4daf-944f-995b2524bbf7"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(eval_model, dataloader, id2label, event_list, device=\"cpu\"):\n",
    "    eval_model.eval()\n",
    "    all_preds_token, all_labels_token = [], []\n",
    "    all_preds_cls, all_labels_cls = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            cls_labels = batch[\"cls_labels\"].to(device)\n",
    "\n",
    "            out = eval_model(input_ids, attention_mask)\n",
    "            token_logits = out[\"token_logits\"].cpu().numpy()\n",
    "            cls_logits = out[\"cls_logits\"].cpu().numpy()\n",
    "\n",
    "            # токены\n",
    "            preds = token_logits.argmax(axis=-1)\n",
    "            all_preds_token.extend(preds.tolist())\n",
    "            all_labels_token.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "            # CLS\n",
    "            all_preds_cls.extend(cls_logits)\n",
    "            all_labels_cls.extend(cls_labels.cpu().numpy())\n",
    "\n",
    "    token_f1 = compute_token_f1(all_preds_token, all_labels_token, id2label)\n",
    "    cls_f1, cls_prec, cls_rec = compute_cls_metrics(\n",
    "        np.array(all_preds_cls), np.array(all_labels_cls)\n",
    "    )\n",
    "    return token_f1, cls_f1, cls_prec, cls_rec\n",
    "\n",
    "print(\"FP32 модель:\")\n",
    "print(evaluate_model(model_cpu, test_dataloader, id2label, event_list))\n",
    "\n",
    "print(\"INT8 модель:\")\n",
    "print(evaluate_model(quantized_model, test_dataloader, id2label, event_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dg09FceV2H1_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "Dg09FceV2H1_",
    "outputId": "60badbc6-6e18-4e09-daba-8839c4e0a099"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(\"\"\"\n",
    "### Выводы\n",
    "1. Модель уверенно предсказывает частые сущности и отношения, но систематически пропускает редкие классы.\n",
    "2. В CLS-задаче заметен избыток ложноположительных меток: модель добавляет отношения, которых нет в тексте.\n",
    "3. Квантизация заметно ускорила инференс (примерно на 25%), качество при этом значительно не пострадало.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10da93ddd3e4410ca79baa62b16d119b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3336893c62e241dea515aaee540c04e9",
      "placeholder": "​",
      "style": "IPY_MODEL_b6dae53ab3544a4a9e8b23b9528d7e8e",
      "value": " 20/20 [00:00&lt;00:00, 262.58 examples/s]"
     }
    },
    "153daf231c684d779192efc7b6282044": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fd9cf57b7694db68e139bd0feab60aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3336893c62e241dea515aaee540c04e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3458397b098146e2a753b6d62950be3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4abd3d15a7b24868948ae78b64a08cb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d2b9279b077468d960b3dd7be69d708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4abd3d15a7b24868948ae78b64a08cb3",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fd9cf57b7694db68e139bd0feab60aa",
      "value": 20
     }
    },
    "7d878f0fb6ea44c49483a5ba56c4e168": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "852b1067fdf24a3fb2ec5af3c29815e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3458397b098146e2a753b6d62950be3a",
      "placeholder": "​",
      "style": "IPY_MODEL_df47ea0d0dc94fd4b8857b8f86648975",
      "value": " 180/180 [00:00&lt;00:00, 504.67 examples/s]"
     }
    },
    "8b13efd9432340babc6059fd1f656554": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c284919bc114d6dbd674db00183d508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "938e56f943df4c35a10b15be474e64ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e603b47036714655af805958cc63076a",
       "IPY_MODEL_cdd29467165a40daa830daba1e91fd17",
       "IPY_MODEL_852b1067fdf24a3fb2ec5af3c29815e9"
      ],
      "layout": "IPY_MODEL_c52358d7b38f4f3db7f2f42cbbc43419"
     }
    },
    "954e0d237a1b45d0acd8ad8112f81be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9dc7a50f7ad2483d9ba05f5969fb4eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f63cec0c09234f27b6af5ea3fe947d83",
      "placeholder": "​",
      "style": "IPY_MODEL_153daf231c684d779192efc7b6282044",
      "value": "Map: 100%"
     }
    },
    "b6dae53ab3544a4a9e8b23b9528d7e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c52358d7b38f4f3db7f2f42cbbc43419": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c63cb1c59ba64c7e926ba6e4a70974cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dc7a50f7ad2483d9ba05f5969fb4eef",
       "IPY_MODEL_7d2b9279b077468d960b3dd7be69d708",
       "IPY_MODEL_10da93ddd3e4410ca79baa62b16d119b"
      ],
      "layout": "IPY_MODEL_7d878f0fb6ea44c49483a5ba56c4e168"
     }
    },
    "cb0f56b4ab794d27807bdb043e288216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdd29467165a40daa830daba1e91fd17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb0f56b4ab794d27807bdb043e288216",
      "max": 180,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_954e0d237a1b45d0acd8ad8112f81be3",
      "value": 180
     }
    },
    "df47ea0d0dc94fd4b8857b8f86648975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e603b47036714655af805958cc63076a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b13efd9432340babc6059fd1f656554",
      "placeholder": "​",
      "style": "IPY_MODEL_8c284919bc114d6dbd674db00183d508",
      "value": "Map: 100%"
     }
    },
    "f63cec0c09234f27b6af5ea3fe947d83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
